# -*- coding: utf-8 -*-
"""eQTL_expression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nJlRUS9f9aFc-HpLKtAPD-OSHVS1Elcl

This notebook generates Figure 2c in the Sei framework manuscript, showing that regulatory sequence-class-level variant effects are predictive of directional GTEx variant gene expression effects.
"""

from google.colab import drive
drive.mount('/content/drive')

from collections import defaultdict
import glob
import os

import numpy as np
import pandas as pd
from scipy.stats import spearmanr
from statsmodels.stats.multitest import multipletests

import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

plt.style.use('seaborn-white')

mpl.rcParams['axes.spines.right'] = False
mpl.rcParams['axes.spines.top'] = False
mpl.rcParams['pdf.fonttype'] = 42
mpl.rcParams['ps.fonttype'] = 42
mpl.rc('xtick', labelsize=24)
mpl.rc('ytick', labelsize=24)
mpl.rc('axes', titlesize=24)
mpl.rc('legend', fontsize=18)

"""We downloaded and processed the [GTEx v8 data](https://storage.googleapis.com/gtex_analysis_v8/single_tissue_qtl_data/GTEx_Analysis_v8_eQTL.tar) and [GENCODE transcript .gtf file](https://storage.googleapis.com/gtex_analysis_v8/reference/gencode.v26.GRCh38.genes.gtf) used in the GTEx analyses. Set the data filepaths accordingly:"""

GTEX_DATA_DIR = '/content/drive/MyDrive/BimaProject/Modig1/Test3/GTEx_Analysis_v8_eQTL'
GENCODE_GTF = '/content/drive/MyDrive/BimaProject/Modig1/Test3/gencode.v26.annotation.gtf'
SEI_DIR = '/content/drive/MyDrive/BimaProject'

SC_NAMES_FILE = os.path.join(RESOURCES_DIR, 'cnames.tsv')
df = pd.read_csv(SC_NAMES_FILE, sep='\t')
df.head()
MAPPING = {}
for row in df.itertuples():
    MAPPING[row.index] = '{0} {1}'.format(row.ID, row.name)

ensg_gene_coordinates = {}
with open(GENCODE_GTF, 'r') as fh:
    for line in fh:
        if '##' in line:
            continue
        cols = line.strip().split('\t')
        coordinates = (cols[0], int(cols[3]), int(cols[4]))
        ensg_id = cols[8].split(';')[0].split(' ')[1][1:-1]
        ensg_gene_coordinates[ensg_id] = coordinates

"""Collect all eQTLs and their effect sizes (slope) for a tissue +/- `N_FROM_TSS` of any gene. Note these next 3 cells will take a few minutes to run."""

#Not
N_FROM_TSS = 5000
tissue_variants_near_tss = defaultdict(list)
for fp in glob.glob(os.path.join(GTEX_DATA_DIR, '*variant_gene_pairs.txt.gz')):
    tissue = os.path.basename(fp).split('.')[0]
    print('Processing {0}'.format(tissue))
    df = pd.read_csv(fp, sep='\t')
    for v, g in zip(df['variant_id'].tolist(), df['gene_id'].tolist()):
        gchrom, gpos, _ = ensg_gene_coordinates[g]
        cols = v.split('_')
        chrom = cols[0]
        pos = int(cols[1])
        if pos >= gpos - N_FROM_TSS and pos <= gpos + N_FROM_TSS:
            record = {'chrom': chrom,
                      'pos': pos,
                      'ref': cols[2],
                      'alt': cols[3],
                      'gene': g}
            tissue_variants_near_tss[tissue].append(record)

# Save to TSV file
output_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/file.tsv'  # Provide the desired output file path
with open(output_filepath, 'w') as file:
    # Write header
    file.write("chrom\tpos\tref\talt\tgene\n")

    # Write data
    for tissue, records in tissue_variants_near_tss.items():
        for record in records:
            file.write("\t".join([str(record[key]) for key in ['chrom', 'pos', 'ref', 'alt', 'gene']]) + "\n")

# Load the Sei_data.xlsx file
sei_data_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/Sei data.xlsx'  # Provide the path to your Sei_data.xlsx file
sei_data_df = pd.read_excel(sei_data_filepath, sheet_name='sorted Filtered sequence_class_')

# Load the previously generated file.tsv
file_tsv_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/file.tsv'  # Provide the path to your file.tsv
file_tsv_df = pd.read_csv(file_tsv_filepath, sep='\t')

# Merge the two dataframes based on chromosome, position, reference allele, and alternate allele
merged_df = pd.merge(sei_data_df, file_tsv_df, on=['chrom', 'pos', 'ref', 'alt'], how='inner')

# Drop duplicates based on the specified columns
merged_df = merged_df.drop_duplicates(subset=['chrom', 'pos', 'ref', 'alt', 'gene'])

# Save the matching variants to a new output TSV file
output_matched_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/matched_file.tsv'  # Provide the desired path for the output file
merged_df.to_csv(output_matched_filepath, sep='\t', index=False, columns=['chrom', 'pos', 'ref', 'alt', 'gene'])

#This is the one that comes after the R code

# Load the Sei_data.xlsx file
sei_data_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/score_extraction.xlsx'  # Provide the path to your Sei_data.xlsx file
sei_data_df = pd.read_excel(sei_data_filepath, sheet_name='Sheet 1')

# Load the previously generated file.tsv
file_tsv_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/file.tsv'  # Provide the path to your file.tsv
file_tsv_df = pd.read_csv(file_tsv_filepath, sep='\t')

# Merge the two dataframes based on chromosome, position, reference allele, and alternate allele
merged_df = pd.merge(sei_data_df, file_tsv_df, on=['chrom', 'pos', 'ref', 'alt'], how='inner')

# Drop duplicates based on the specified columns
merged_df = merged_df.drop_duplicates(subset=['chrom', 'pos', 'ref', 'alt', 'gene'])

# Save the matching variants to a new output TSV file
output_matched_filepath = '/content/drive/MyDrive/BimaProject/Modig1/Test3/matched_file2.tsv'  # Provide the desired path for the output file
merged_df.to_csv(output_matched_filepath, sep='\t', index=False, columns=['chrom', 'pos', 'ref', 'alt', 'gene','Sequence class scores','Sequence class'])

fn_vid_slopes = defaultdict(dict)
for fp in glob.glob(os.path.join(GTEX_DATA_DIR, '*variant_gene_pairs.txt.gz')):
    df = pd.read_csv(fp, sep='\t')
    fn = os.path.basename(fp).split('.')[0]
    for r in df.itertuples():
        vcols = r.variant_id.split('_')
        vid = (vcols[0], int(vcols[1]), vcols[2], vcols[3])
        fn_vid_slopes[fn][vid] = r.slope

variants = set()
for fp in glob.glob(os.path.join(GTEX_DATA_DIR, '*variant_gene_pairs.txt.gz')):
    fn = os.path.basename(fp).split('.')[0]
    df = pd.read_csv(fp, sep='\t')
    variants_set = set(df['variant_id'].tolist())
    variants |= variants_set

variant_records = []
for v in variants:
    cols = v.split('_')
    record = {'chrom': cols[0],
              'pos': int(cols[1]),
              'ref': cols[2], 'alt': cols[3]}
    variant_records.append(record)

variants_df = pd.DataFrame.from_records(variant_records)
variants_df.sort_values(['chrom', 'pos'], inplace=True)
variants_df = variants_df[['chrom', 'pos', 'ref', 'alt']]
all_variants = variants_df.to_records()

"""We have saved the Sei predictions for 1000 Genomes variants (which we use in another analysis). `chrom_start_tags.npy` and `chrom_end_tags.npy` are used just to figure out which files of Sei predictions we query in order to get the eQTL (variant) effect predictions for the GTEx tissues."""

TAGS = np.load(os.path.join(
    SEI_DIR, 'Filtered.sequence_class_scores.npy'), allow_pickle=True).item()
END_TAGS = np.load(os.path.join(
    SEI_DIR, 'chrom_end_tags.npy'), allow_pickle=True).item()
tags = set(END_TAGS.values()) | set(START_TAGS.values())
tags = sorted(tags)

def populate_dict(lt):
    file_tag_dict = defaultdict(list)
    not_matched = []
    for row in lt:
        chrom = row[1]
        pos = row[2]
        ref = row[3]
        alt = row[4]
        in_s_tags = []
        in_e_tags = []
        for (schrom, spos), tag in START_TAGS.items():
            if schrom == chrom and pos >= spos:
                in_s_tags.append(tag)
        for (echrom, epos), tag in END_TAGS.items():
            if echrom == chrom and pos <= epos:
                in_e_tags.append(tag)
        match_tag = list(set(in_s_tags) & set(in_e_tags))
        if len(match_tag) != 1:
            not_matched.append(row)
        else:
            file_tag_dict[match_tag[0]].append((chrom, pos, ref, alt))
    return file_tag_dict, not_matched

gtex_tag_1000G, gtex_nm = populate_dict(all_variants)

"""(There are <0.02% variants that weren't mapped from the existing set of predictions)"""

N_eQTLs = 0
for lt in gtex_tag_1000G.values():
    N_eQTLs += len(lt)
len(gtex_nm), N_eQTLs

"""Get the sequence class variant effect scores for the GTEx eQTLs. This will take a few minutes to run."""

def get_scores(data_dir, score="diffs"):
    all_scores = []
    all_dfs = []
    for tag in tags:
        print(tag)
        lt = gtex_tag_1000G[tag]
        scores = np.load(os.path.join(
            data_dir, '1000Genomes.{0}.{1}.npy'.format(tag, score)))
        rows_fp = os.path.join(
            SEI_DIR, '1000G_vcfs', '1000Genomes.{0}.vcf'.format(tag))
        df = pd.read_csv(rows_fp, sep='\t', header=None)
        df.columns = ['chrom', 'pos', 'id', 'ref', 'alt']
        df['chrom'] = 'chr' + df['chrom'].astype(str)

        index = list(df.index)  # this means the index will match the row labels file
        df.set_index(['chrom', 'pos', 'ref', 'alt'], inplace=True)
        df['ix'] = index
        subset_df = df.loc[df.index.intersection(lt)]
        subset_df.sort_values(['chrom', 'pos'], inplace=True)
        subset_ixs = [int(ix) for ix in subset_df['ix']]
        score_subset = scores[subset_ixs]
        all_scores.append(score_subset)
        all_dfs.append(subset_df)
    return np.vstack(all_scores), pd.concat(all_dfs)

SCORE_DIR = os.path.join(SEI_DIR, "1000G_EUR_seqclass_scores")
seqclass_diffs, seqclass_diff_df = get_scores(SCORE_DIR, score='diffs')

seqclass_diff_df['row_ix'] = list(range(len(seqclass_diff_df)))

seqclass_diff_df.head()

"""Compute the Spearman's rank correlation for the top 15,000 sequence class variant effect scores and the corresponding eQTL effect sizes (slope)."""

def get_diff_predictions(diff_data, diff_df):
    all_diff_predictions = []
    all_slopes = []
    all_variants = []
    for fn, records in tissue_variants_near_tss.items():
        variants = [(r['chrom'], r['pos'], r['ref'], r['alt']) for r in records]
        subset_df = diff_df.loc[diff_df.index.intersection(variants)]
        subset_data = diff_data[subset_df['row_ix'].tolist()]
        all_diff_predictions.append(subset_data)

        subset_variants = subset_df.index.tolist()
        for v in subset_variants:
            all_slopes.append(fn_vid_slopes[fn][v])
            all_variants.append('_'.join([str(x) for x in v]))

    return np.vstack(all_diff_predictions), np.array(all_slopes), np.array(all_variants)

def get_seqclass_slope_correlations_no_dups(input_diff_data,
                                            input_slopes,
                                            input_variants,
                                            use_N=15000):
    corrs = defaultdict(float)
    pvalues = defaultdict(float)
    sds = defaultdict(float)
    avgs = defaultdict(float)
    clusters = []
    for c in range(40):
        if 'HET' in MAPPING[c] or 'Low' in MAPPING[c]:
            continue
        clusters.append(c)
        top_ixs = np.argsort(-1 * np.abs(input_diff_data[:, c]))
        top_diffs = input_diff_data[top_ixs[:use_N], c]
        top_slopes = input_slopes[top_ixs[:use_N]]
        top_variants = input_variants[top_ixs[:use_N]]

        top_avg_slopes = defaultdict(list)
        corresponding_diffs = {}
        for i, v in enumerate(top_variants):
            if v not in corresponding_diffs:
                corresponding_diffs[v] = top_diffs[i]
            top_avg_slopes[v].append(top_slopes[i])

        top_diffs = [corresponding_diffs[k] for k in top_avg_slopes.keys()]
        top_slopes = [np.average(slopes) for slopes in top_avg_slopes.values()]
        r, p = spearmanr(top_diffs, top_slopes)
        corrs[c] = r
        pvalues[c] = p
        sds[c] = np.std(np.abs(top_diffs))
        avgs[c] = np.average(np.abs(top_diffs))

    pvalues = np.array([pvalues[c] for c in clusters])
    corrs = np.array([corrs[c] for c in clusters])
    sds = np.array([sds[c] for c in clusters])
    avgs = np.array([avgs[c] for c in clusters])

    reject, pvs_corrected, _, _ = multipletests(
        pvalues, alpha=0.01, method='fdr_bh', is_sorted=False)
    for i, (corr, sd, pv) in enumerate(zip(corrs, sds, pvs_corrected)):
        print(i, corr, sd, -np.log10(pv), pv < 0.05)
    return np.array(clusters), corrs, pvs_corrected, sds, avgs

sc_near_tss, sc_slopes, sc_variants = get_diff_predictions(seqclass_diffs, seqclass_diff_df)

seqclasses, sc_corrs, sc_pvs, sc_sds, sc_avgs = get_seqclass_slope_correlations_no_dups(
    sc_near_tss, sc_slopes, sc_variants, use_N=15000)

"""Visualize the results"""

def num_split(s):
    head = s.rstrip('0123456789')
    tail = s[len(head):]
    return head, tail

class_categories = defaultdict(list)
for c, label in MAPPING.items():
    classname = label.split(' ')[0]
    classtype, _ = num_split(classname)
    class_categories[classtype].append(c)
class_categories

color_map = {
    'E': "#984ef3",
    'CTCF': "#fdb462",
    'P': "#ef3b2c",
    'PC': "#8abad4",
    'HET': "#662506",
    'TN': "#fb9a99",
    'TF': "#386cb0",
    'L': "#C0C0C0"
}

def plot_corr_stddev_volcano(clusters, corrs, fdrs, avg_diffs, savefile):
    corrs = corrs
    corr_sorted_ixs = np.argsort(-1 * corrs)
    corrs = corrs[corr_sorted_ixs]
    fdrs = fdrs[corr_sorted_ixs]
    clusters = clusters[corr_sorted_ixs]
    avg_diffs = avg_diffs[corr_sorted_ixs]

    pass_fdrs = fdrs[fdrs < 0.05]
    pass_corrs = corrs[fdrs < 0.05]
    rem_fdrs = fdrs[fdrs >= 0.05]
    rem_corrs = corrs[fdrs >= 0.05]

    fig = plt.figure(figsize=(13, 10))
    ax = fig.add_subplot(1, 1, 1)

    for label, classes in class_categories.items():
        inter = np.in1d(clusters[fdrs < 0.05], classes)
        ax.scatter(pass_corrs[inter], -np.log10(pass_fdrs)[inter],
                   marker='o',
                   s=100 + 15*-np.log10(pass_fdrs[inter]),
                   alpha=0.7,
                   color=color_map[label])
        for c, x, y in zip(clusters[fdrs < 0.05][inter],
                           pass_corrs[inter],
                           -np.log10(pass_fdrs)[inter]):
            print(MAPPING[c], x, y)
            ax.annotate(MAPPING[c], (x, y), fontsize=24)

    ax.scatter(rem_corrs, -np.log10(rem_fdrs),
               marker='X', s=80, color='lightgray',
               label='NS (fdr > 0.05)')
    for c, x, y in zip(clusters[fdrs >= 0.05],
                        rem_corrs,
                        -np.log10(rem_fdrs)):
        ax.annotate(MAPPING[c].split(' ')[0], (x, y), fontsize=22, c='#C0C0C0')

    ax.spines['left'].set_position('center')

    ax.legend(frameon=True, loc='lower right')

    ax.set_xlabel("Spearman's correlation", fontsize=20)
    ax.set_ylabel('-log10(p-value)', fontsize=20)
    s, e = -1 * np.max(np.abs(corrs)), np.max(np.abs(corrs))
    s += 0.01
    e += 0.01
    print(s, e)
    ax.set_xlim([s, e])
    plt.plot([s, e], [-np.log10(0.05), -np.log10(0.05)], linewidth=0.75, linestyle='--', c='gray')
    plt.tight_layout()
    plt.savefig(savefile, dpi=300)

plot_corr_stddev_volcano(seqclasses, sc_corrs, sc_pvs, sc_avgs,
    os.path.join(FIGS_DIR, 'threshold.gtex_slope.corr_pvalues.seqclass_variant_effects.pdf'))